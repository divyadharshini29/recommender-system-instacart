{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from implicit.nearest_neighbours import tfidf_weight\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from numpy import bincount, log, sqrt\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "import implicit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def sparsity(matrix):\n",
    "    total_size = matrix.shape[0] * matrix.shape[1]\n",
    "    actual_size = matrix.size\n",
    "    sparsity = (1 - (actual_size / total_size)) * 100\n",
    "    return(sparsity)\n",
    "\n",
    "\n",
    "def timestamp():\n",
    "    now = datetime.now()\n",
    "    return \"{}_{}_{}_{}{}\".format(now.year, now.month, now.day, now.hour, now.minute)\n",
    "\n",
    "\n",
    "def get_k_popular(k, df_merged_order_products_prior):\n",
    "    popular_products = list(df_merged_order_products_prior[\"product_id\"].value_counts().head(k).index)\n",
    "    return popular_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order datasets\n",
    "df_order_products_prior = pd.read_csv(\"../data/order_products__prior.csv\")\n",
    "df_order_products_train = pd.read_csv(\"../data/order_products__train.csv\")\n",
    "df_orders = pd.read_csv(\"../data/orders.csv\") \n",
    "\n",
    "# Products\n",
    "df_products = pd.read_csv(\"../data/products.csv\")\n",
    "# Merge prior orders and products\n",
    "df_merged_order_products_prior = pd.merge(df_order_products_prior, df_products, on=\"product_id\", how=\"left\")\n",
    "\n",
    "# Read user_products and product_frequency from the disk\n",
    "df_prior_user_products = pd.read_pickle(\"../dataframes/cb/cb_user_products.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_data(test_data_path, df_orders, df_order_products_train):\n",
    "    start = time.time()\n",
    "    print(\"Creating test data ...\")\n",
    "\n",
    "    # Read train csv\n",
    "    df_order_user_current = df_orders.loc[(df_orders.eval_set == \"train\")].reset_index()\n",
    "    df_order_user_current = df_order_user_current[[\"order_id\", \"user_id\"]]\n",
    "    \n",
    "    # Sanity check #1: `current_order_user_df` and `df_order_products_train` should have the same number of \n",
    "    # unique order ids\n",
    "    assert len(df_order_user_current[\"order_id\"].unique()) == len(df_order_products_train[\"order_id\"].unique())\n",
    "\n",
    "    # Convert train dataframe to a similar format\n",
    "    df_order_products_test = df_order_products_train[[\"order_id\", \"product_id\"]]\n",
    "    df_order_products_test = df_order_products_test.groupby(\"order_id\")[\"product_id\"].apply(list).reset_index().rename(columns={\"product_id\": \"products\"})\n",
    "\n",
    "    # Sanity check #2: `df_order_products_test` and `df_order_user_current` should have the same number of \n",
    "    # records before attempting to merge them\n",
    "    assert df_order_products_test.size == df_order_user_current.size\n",
    "\n",
    "    # Merge on order id\n",
    "    df_user_products_test = pd.merge(df_order_user_current, df_order_products_test, on=\"order_id\")\n",
    "    df_user_products_test = df_user_products_test[[\"user_id\", \"products\"]]\n",
    "\n",
    "    # Write to disk\n",
    "    df_user_products_test.to_csv(test_data_path, index_label=False)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "\n",
    "\n",
    "# Get test data\n",
    "REBUILD_TEST_DATA = False\n",
    "test_data_path = \"../data/user_products__test.csv\"\n",
    "if REBUILD_TEST_DATA or not Path(test_data_path).is_file():\n",
    "    make_test_data(test_data_path, df_orders, df_order_products_train)\n",
    "df_user_products_test = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[196, 25133, 38928, 26405, 39657, 10258, 13032...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[22963, 7963, 16589, 32792, 41787, 22825, 1364...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>[15349, 19057, 16185, 21413, 20843, 20114, 482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>[12053, 47272, 37999, 13198, 43967, 40852, 176...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>[15937, 5539, 10960, 23165, 22247, 4853, 27104...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                           products\n",
       "0        1  [196, 25133, 38928, 26405, 39657, 10258, 13032...\n",
       "1        2  [22963, 7963, 16589, 32792, 41787, 22825, 1364...\n",
       "2        5  [15349, 19057, 16185, 21413, 20843, 20114, 482...\n",
       "3        7  [12053, 47272, 37999, 13198, 43967, 40852, 176...\n",
       "4        8  [15937, 5539, 10960, 23165, 22247, 4853, 27104..."
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_products_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "2    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func(row):\n",
    "    print(row[\"user_id\"])\n",
    "\n",
    "df_user_products_test[:3].apply(func, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Product Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_product_prior_df(filepath, df_orders, df_order_products_prior):\n",
    "    start = time.time()\n",
    "    print(\"Creating prior user product data frame ...\")\n",
    "    \n",
    "    # Consider ony \"prior\" orders and remove all columns except `user_id` from `df_orders`\n",
    "    df_order_user_prior = df_orders.loc[df_orders.eval_set == \"prior\"]\n",
    "    df_order_user_prior = df_order_user_prior[[\"order_id\", \"user_id\"]]\n",
    "    \n",
    "    # Remove all columns except order_id and user_id from df_orders and \n",
    "    # merge the above on `order_id` and remove `order_id`\n",
    "    df_merged = pd.merge(df_order_user_prior, df_order_products_prior[[\"order_id\", \"product_id\"]], on=\"order_id\")\n",
    "    df_user_product_prior = df_merged[[\"user_id\", \"product_id\"]]\n",
    "    df_user_product_prior = df_user_product_prior.groupby([\"user_id\", \"product_id\"]).size().reset_index().rename(columns={0:\"quantity\"})\n",
    "    \n",
    "    # Write to disk\n",
    "    df_user_product_prior.to_csv(filepath, index_label=False)\n",
    "\n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "\n",
    "\n",
    "# Build dataframe of users, products and quantity bought using prior datasets\n",
    "REBUILD_MATRIX_DF = False\n",
    "matrix_df_path = \"../data/user_products__prior.csv\"\n",
    "if REBUILD_MATRIX_DF or not Path(matrix_df_path).is_file():\n",
    "    get_user_product_prior_df(matrix_df_path, df_orders, df_order_products_prior)\n",
    "df_user_product_prior = pd.read_csv(matrix_df_path)\n",
    "df_user_product_prior[\"user_id\"] = df_user_product_prior[\"user_id\"].astype(\"category\")\n",
    "df_user_product_prior[\"product_id\"] = df_user_product_prior[\"product_id\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_product_user_matrix(matrix_path, df_user_product_prior):\n",
    "    start = time.time()\n",
    "    print(\"Creating product user matrix ...\")\n",
    "    \n",
    "    # Make the dataframe a sparse matrix\n",
    "    df_user_product_prior[\"user_id\"] = df_user_product_prior[\"user_id\"].astype(\"category\")\n",
    "    df_user_product_prior[\"product_id\"] = df_user_product_prior[\"product_id\"].astype(\"category\")\n",
    "    product_user_matrix = sparse.coo_matrix((df_user_product_prior[\"quantity\"],\n",
    "                                            (df_user_product_prior[\"product_id\"].cat.codes.copy(),\n",
    "                                             df_user_product_prior[\"user_id\"].cat.codes.copy())))\n",
    "    \n",
    "    sparse.save_npz(matrix_path, product_user_matrix)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "\n",
    "\n",
    "# Get the `product x user` matrix\n",
    "REBUILD_MATRIX = False\n",
    "matrix_path = \"../data/product_user_matrix.npz\"\n",
    "if REBUILD_MATRIX or not Path(matrix_path).is_file():\n",
    "    build_product_user_matrix(matrix_path, df_user_product_prior)\n",
    "product_user_matrix = sparse.load_npz(matrix_path).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# User=1 bought product=196 10 times\n",
    "assert product_user_matrix[195, 0] == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.8700882953749"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity(product_user_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_product_matrix = product_user_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_weight(X):\n",
    "    \"\"\" Weights a Sparse Matrix by TF-IDF Weighted \"\"\"\n",
    "    X = coo_matrix(X)\n",
    "\n",
    "    # calculate IDF\n",
    "    N = float(X.shape[0])\n",
    "    idf = log(N / (1 + bincount(X.col)))\n",
    "\n",
    "    # apply TF-IDF adjustment\n",
    "    X.data = sqrt(X.data) * idf[X.col]\n",
    "    return X\n",
    "\n",
    "tf_idf = tfidf_weight(user_product_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = tf_idf.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_user_id = 1\n",
    "target_user = tf_idf[target_user_id - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206209, 49677)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 0.26s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "similarities = cosine_similarity(tf_idf, target_user, False)\n",
    "print(\"Completed in {:.2f}s\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "cos_vec = similarities.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateRecommendations(target_user, cos_vec, K, N, df_prior_user_products):\n",
    "    # Select top K similar users\n",
    "    top_K_similar_users = heapq.nlargest(K+1, range(len(cos_vec)), cos_vec.take)\n",
    "    \n",
    "    # Exclude the user with same purchase history (1.00000) as the target user and implement set-minus\n",
    "    products_target_user = df_prior_user_products.loc[df_prior_user_products['user_id'] == target_user_id].products\n",
    "\n",
    "    # Initialize the result for recommendations\n",
    "    recommendations = []\n",
    "\n",
    "    # Products of Target User\n",
    "    productset_target_user = set(products_target_user.tolist()[0])\n",
    "\n",
    "    # Fetch the preliminary recommendations\n",
    "    for similar_user_id in top_K_similar_users:\n",
    "        \n",
    "        products_similar_user = df_prior_user_products.loc[df_prior_user_products['user_id'] == similar_user_id + 1].products\n",
    "\n",
    "        # Recommend the products bought by the user who firstly differs in the purchase history from A.\n",
    "        candidate_recommendation = set(products_similar_user.tolist()[0]).intersection(productset_target_user)\n",
    "\n",
    "        # If similar_user_id equals to target_user_id or the candidate_recommendation is empty,\n",
    "        # skip current user\n",
    "        if similar_user_id == target_user_id or not candidate_recommendation: continue\n",
    "\n",
    "        # One candidate_recommendation found, and extend it to the result\n",
    "        recommendations.extend(candidate_recommendation)\n",
    "\n",
    "#         If length of recommendations exceed N, break\n",
    "        if len(recommendations) > N: break\n",
    "            \n",
    "    return productset_target_user, recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "productset_target_user, recommendations = generateRecommendations(target_user, similarities.toarray(), 20, 20, df_prior_user_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual products bought by User 1:\n",
      "['Organic Honeydew', 'Cold Brew Coffee Tahitian Vanilla', \"Spot's Pate Cat Grain Free Ground Whitefish\", 'Epic Fruit & Yogurt Filled Pouches', 'Beet Kombucha', 'Broccoli Squash Carrots Onion Red Pepper Steamables', 'Grape Nut Flakes Cereal', 'Triple Distilled Irish Whiskey', \"Steam'ables Green Peas\", 'Cilantro Bunch', 'Peachtree Schnapps', 'Original Pretzel Crisps', 'Chocolate Caramel Pudding Snack Pack', 'Pasta & Enchilada Sauce, Organic, 7 Veggie', '80% Lean Ground Beef', 'Creamy Chicken & Shrimp in a Parmesan Alfredo Sauce', 'Warrior Blend Vanilla Dietary Supplement', 'Organic Creamy Cashewmilk']\n",
      "\n",
      "Recommended products for User 1:\n",
      "['Organic Honeydew', 'Cold Brew Coffee Tahitian Vanilla', 'Beet Kombucha', \"Spot's Pate Cat Grain Free Ground Whitefish\", 'Epic Fruit & Yogurt Filled Pouches', 'Broccoli Squash Carrots Onion Red Pepper Steamables', 'Grape Nut Flakes Cereal', 'Triple Distilled Irish Whiskey', \"Steam'ables Green Peas\", 'Cilantro Bunch', 'Peachtree Schnapps', 'Original Pretzel Crisps', 'Chocolate Caramel Pudding Snack Pack', 'Pasta & Enchilada Sauce, Organic, 7 Veggie', '80% Lean Ground Beef', 'Creamy Chicken & Shrimp in a Parmesan Alfredo Sauce', 'Warrior Blend Vanilla Dietary Supplement', 'Organic Creamy Cashewmilk', 'Warrior Blend Vanilla Dietary Supplement', 'Chocolate Caramel Pudding Snack Pack', \"Steam'ables Green Peas\"]\n"
     ]
    }
   ],
   "source": [
    "# Output the product_name of Target User's products as well as Recommendations\n",
    "print('Actual products bought by User {}:'.format(target_user_id))\n",
    "print([df_products.iloc[product_id]['product_name'] for product_id in productset_target_user])\n",
    "print()\n",
    "print('Recommended products for User {}:'.format(target_user_id))\n",
    "print([df_products.iloc[item]['product_name'] for item in recommendations])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the 10 most popular products\n",
    "popular_products = get_k_popular(10, df_merged_order_products_prior)\n",
    "\n",
    "# Maps user_id: user_cat_code\n",
    "u_dict = {uid:i for i, uid in enumerate(df_user_product_prior[\"user_id\"].cat.categories)}\n",
    "\n",
    "# Maps product_cat_code: product_id\n",
    "p_dict = dict(enumerate(df_user_product_prior[\"product_id\"].cat.categories))\n",
    "\n",
    "# Transpose of the product_user_matrix\n",
    "user_product_matrix = product_user_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataframe with recall values ...\n",
      "0.20% completed, recall_score = 0.91\n",
      "0.40% completed, recall_score = 0.03\n",
      "0.60% completed, recall_score = 0.00\n",
      "0.80% completed, recall_score = 0.00\n",
      "1.00% completed, recall_score = 0.00\n",
      "1.20% completed, recall_score = 0.00\n",
      "1.40% completed, recall_score = 0.00\n",
      "1.60% completed, recall_score = 0.00\n",
      "1.80% completed, recall_score = 0.00\n",
      "2.00% completed, recall_score = 0.00\n",
      "2.20% completed, recall_score = 0.00\n",
      "2.40% completed, recall_score = 0.00\n",
      "2.60% completed, recall_score = 0.00\n",
      "2.80% completed, recall_score = 0.00\n",
      "3.00% completed, recall_score = 0.00\n",
      "3.20% completed, recall_score = 0.00\n",
      "3.40% completed, recall_score = 0.00\n",
      "3.60% completed, recall_score = 0.00\n",
      "3.80% completed, recall_score = 0.00\n",
      "4.00% completed, recall_score = 0.00\n",
      "4.20% completed, recall_score = 0.00\n",
      "4.40% completed, recall_score = 0.00\n",
      "4.60% completed, recall_score = 0.00\n",
      "4.80% completed, recall_score = 0.00\n",
      "5.00% completed, recall_score = 0.00\n",
      "5.20% completed, recall_score = 0.00\n",
      "5.40% completed, recall_score = 0.00\n",
      "5.60% completed, recall_score = 0.00\n",
      "5.80% completed, recall_score = 0.17\n",
      "6.00% completed, recall_score = 0.18\n",
      "6.20% completed, recall_score = 0.00\n",
      "6.40% completed, recall_score = 0.00\n",
      "6.60% completed, recall_score = 0.00\n",
      "6.80% completed, recall_score = 0.05\n",
      "7.00% completed, recall_score = 0.00\n",
      "7.20% completed, recall_score = 0.07\n",
      "7.40% completed, recall_score = 0.06\n",
      "7.60% completed, recall_score = 0.00\n",
      "7.80% completed, recall_score = 0.00\n",
      "8.00% completed, recall_score = 0.67\n",
      "8.20% completed, recall_score = 0.00\n",
      "8.40% completed, recall_score = 0.00\n",
      "8.60% completed, recall_score = 0.00\n",
      "8.80% completed, recall_score = 0.00\n",
      "9.00% completed, recall_score = 0.00\n",
      "9.20% completed, recall_score = 0.00\n",
      "9.40% completed, recall_score = 0.10\n",
      "9.60% completed, recall_score = 0.09\n",
      "9.80% completed, recall_score = 0.00\n",
      "10.00% completed, recall_score = 0.29\n",
      "10.20% completed, recall_score = 0.00\n",
      "10.40% completed, recall_score = 0.08\n",
      "10.60% completed, recall_score = 0.06\n",
      "10.80% completed, recall_score = 0.00\n",
      "11.00% completed, recall_score = 0.00\n",
      "11.20% completed, recall_score = 0.07\n",
      "11.40% completed, recall_score = 0.00\n",
      "11.60% completed, recall_score = 0.03\n",
      "11.80% completed, recall_score = 0.00\n",
      "12.00% completed, recall_score = 0.00\n",
      "12.20% completed, recall_score = 0.00\n",
      "12.40% completed, recall_score = 0.00\n",
      "12.60% completed, recall_score = 0.07\n",
      "12.80% completed, recall_score = 0.00\n",
      "13.00% completed, recall_score = 0.00\n",
      "13.20% completed, recall_score = 0.00\n",
      "13.40% completed, recall_score = 0.00\n",
      "13.60% completed, recall_score = 0.00\n",
      "13.80% completed, recall_score = 0.00\n",
      "14.00% completed, recall_score = 0.00\n",
      "14.20% completed, recall_score = 0.05\n",
      "14.40% completed, recall_score = 0.04\n",
      "14.60% completed, recall_score = 0.00\n",
      "14.80% completed, recall_score = 0.00\n",
      "15.00% completed, recall_score = 0.00\n",
      "15.20% completed, recall_score = 0.08\n",
      "15.40% completed, recall_score = 0.00\n",
      "15.60% completed, recall_score = 0.00\n",
      "15.80% completed, recall_score = 0.25\n",
      "16.00% completed, recall_score = 0.00\n",
      "16.20% completed, recall_score = 0.00\n",
      "16.40% completed, recall_score = 0.00\n",
      "16.60% completed, recall_score = 0.09\n",
      "16.80% completed, recall_score = 0.00\n",
      "17.00% completed, recall_score = 0.00\n",
      "17.20% completed, recall_score = 0.00\n",
      "17.40% completed, recall_score = 0.00\n",
      "17.60% completed, recall_score = 0.00\n",
      "17.80% completed, recall_score = 0.00\n",
      "18.00% completed, recall_score = 0.00\n",
      "18.20% completed, recall_score = 0.00\n",
      "18.40% completed, recall_score = 0.00\n",
      "18.60% completed, recall_score = 0.04\n",
      "18.80% completed, recall_score = 0.00\n",
      "19.00% completed, recall_score = 0.00\n",
      "19.20% completed, recall_score = 0.00\n",
      "19.40% completed, recall_score = 0.00\n",
      "19.60% completed, recall_score = 0.00\n",
      "19.80% completed, recall_score = 0.00\n",
      "20.00% completed, recall_score = 0.00\n",
      "20.20% completed, recall_score = 0.00\n",
      "20.40% completed, recall_score = 0.00\n",
      "20.60% completed, recall_score = 0.12\n",
      "20.80% completed, recall_score = 0.00\n",
      "21.00% completed, recall_score = 0.00\n",
      "21.20% completed, recall_score = 0.00\n",
      "21.40% completed, recall_score = 0.00\n",
      "21.60% completed, recall_score = 0.00\n",
      "21.80% completed, recall_score = 0.00\n",
      "22.00% completed, recall_score = 0.00\n",
      "22.20% completed, recall_score = 0.00\n",
      "22.40% completed, recall_score = 0.00\n",
      "22.60% completed, recall_score = 0.00\n",
      "22.80% completed, recall_score = 0.00\n",
      "23.00% completed, recall_score = 0.00\n",
      "23.20% completed, recall_score = 0.00\n",
      "23.40% completed, recall_score = 0.00\n",
      "23.60% completed, recall_score = 0.00\n",
      "23.80% completed, recall_score = 0.00\n",
      "24.00% completed, recall_score = 0.00\n",
      "24.20% completed, recall_score = 0.20\n",
      "24.40% completed, recall_score = 0.14\n",
      "24.60% completed, recall_score = 0.25\n",
      "24.80% completed, recall_score = 0.14\n",
      "25.00% completed, recall_score = 0.00\n",
      "25.20% completed, recall_score = 0.00\n",
      "25.40% completed, recall_score = 0.00\n",
      "25.60% completed, recall_score = 0.00\n",
      "25.80% completed, recall_score = 0.00\n",
      "26.00% completed, recall_score = 0.00\n",
      "26.20% completed, recall_score = 0.00\n",
      "26.40% completed, recall_score = 0.00\n",
      "26.60% completed, recall_score = 0.00\n",
      "26.80% completed, recall_score = 0.00\n",
      "27.00% completed, recall_score = 0.00\n",
      "27.20% completed, recall_score = 0.00\n",
      "27.40% completed, recall_score = 0.00\n",
      "27.60% completed, recall_score = 0.00\n",
      "27.80% completed, recall_score = 0.00\n",
      "28.00% completed, recall_score = 0.00\n",
      "28.20% completed, recall_score = 0.00\n",
      "28.40% completed, recall_score = 0.00\n",
      "28.60% completed, recall_score = 0.00\n",
      "28.80% completed, recall_score = 0.00\n",
      "29.00% completed, recall_score = 0.00\n",
      "29.20% completed, recall_score = 0.00\n",
      "29.40% completed, recall_score = 0.00\n",
      "29.60% completed, recall_score = 0.00\n",
      "29.80% completed, recall_score = 0.00\n",
      "30.00% completed, recall_score = 0.00\n",
      "30.20% completed, recall_score = 0.00\n",
      "30.40% completed, recall_score = 0.06\n",
      "30.60% completed, recall_score = 0.00\n",
      "30.80% completed, recall_score = 0.00\n",
      "31.00% completed, recall_score = 0.09\n",
      "31.20% completed, recall_score = 0.50\n",
      "31.40% completed, recall_score = 0.00\n",
      "31.60% completed, recall_score = 0.00\n",
      "31.80% completed, recall_score = 0.18\n",
      "32.00% completed, recall_score = 0.00\n",
      "32.20% completed, recall_score = 0.00\n",
      "32.40% completed, recall_score = 0.00\n",
      "32.60% completed, recall_score = 0.00\n",
      "32.80% completed, recall_score = 0.00\n",
      "33.00% completed, recall_score = 0.00\n",
      "33.20% completed, recall_score = 0.00\n",
      "33.40% completed, recall_score = 0.00\n",
      "33.60% completed, recall_score = 0.00\n",
      "33.80% completed, recall_score = 0.00\n",
      "34.00% completed, recall_score = 0.00\n",
      "34.20% completed, recall_score = 0.04\n",
      "34.40% completed, recall_score = 0.00\n",
      "34.60% completed, recall_score = 0.14\n",
      "34.80% completed, recall_score = 0.00\n",
      "35.00% completed, recall_score = 0.00\n",
      "35.20% completed, recall_score = 0.10\n",
      "35.40% completed, recall_score = 0.00\n",
      "35.60% completed, recall_score = 0.09\n",
      "35.80% completed, recall_score = 0.00\n",
      "36.00% completed, recall_score = 0.00\n",
      "36.20% completed, recall_score = 0.15\n",
      "36.40% completed, recall_score = 0.00\n",
      "36.60% completed, recall_score = 0.00\n",
      "36.80% completed, recall_score = 0.00\n",
      "37.00% completed, recall_score = 0.09\n",
      "37.20% completed, recall_score = 0.00\n",
      "37.40% completed, recall_score = 0.06\n",
      "37.60% completed, recall_score = 0.00\n",
      "37.80% completed, recall_score = 0.00\n",
      "38.00% completed, recall_score = 0.00\n",
      "38.20% completed, recall_score = 0.00\n",
      "38.40% completed, recall_score = 0.00\n",
      "38.60% completed, recall_score = 0.00\n",
      "38.80% completed, recall_score = 0.00\n",
      "39.00% completed, recall_score = 0.00\n",
      "39.20% completed, recall_score = 0.00\n",
      "39.40% completed, recall_score = 0.00\n",
      "39.60% completed, recall_score = 0.00\n",
      "39.80% completed, recall_score = 0.00\n",
      "40.00% completed, recall_score = 0.00\n",
      "40.20% completed, recall_score = 0.00\n",
      "40.40% completed, recall_score = 0.00\n",
      "40.60% completed, recall_score = 0.00\n",
      "40.80% completed, recall_score = 0.09\n",
      "41.00% completed, recall_score = 0.00\n",
      "41.20% completed, recall_score = 0.00\n",
      "41.40% completed, recall_score = 0.00\n",
      "41.60% completed, recall_score = 0.00\n",
      "41.80% completed, recall_score = 0.00\n",
      "42.00% completed, recall_score = 0.00\n",
      "42.20% completed, recall_score = 0.00\n",
      "42.40% completed, recall_score = 0.00\n",
      "42.60% completed, recall_score = 0.00\n",
      "42.80% completed, recall_score = 0.00\n",
      "43.00% completed, recall_score = 0.00\n",
      "43.20% completed, recall_score = 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.40% completed, recall_score = 0.00\n",
      "43.60% completed, recall_score = 0.00\n",
      "43.80% completed, recall_score = 0.00\n",
      "44.00% completed, recall_score = 0.00\n",
      "44.20% completed, recall_score = 0.00\n",
      "44.40% completed, recall_score = 0.00\n",
      "44.60% completed, recall_score = 0.00\n",
      "44.80% completed, recall_score = 0.00\n",
      "45.00% completed, recall_score = 0.12\n",
      "45.20% completed, recall_score = 0.06\n",
      "45.40% completed, recall_score = 0.00\n",
      "45.60% completed, recall_score = 0.05\n",
      "45.80% completed, recall_score = 0.00\n",
      "46.00% completed, recall_score = 0.00\n",
      "46.20% completed, recall_score = 0.00\n",
      "46.40% completed, recall_score = 0.00\n",
      "46.60% completed, recall_score = 0.00\n",
      "46.80% completed, recall_score = 0.00\n",
      "47.00% completed, recall_score = 0.50\n",
      "47.20% completed, recall_score = 0.00\n",
      "47.40% completed, recall_score = 0.00\n",
      "47.60% completed, recall_score = 0.00\n",
      "47.80% completed, recall_score = 0.00\n",
      "48.00% completed, recall_score = 0.00\n",
      "48.20% completed, recall_score = 0.00\n",
      "48.40% completed, recall_score = 0.00\n",
      "48.60% completed, recall_score = 0.00\n",
      "48.80% completed, recall_score = 0.00\n",
      "49.00% completed, recall_score = 0.00\n",
      "49.20% completed, recall_score = 0.00\n",
      "49.40% completed, recall_score = 0.03\n",
      "49.60% completed, recall_score = 0.10\n",
      "49.80% completed, recall_score = 0.06\n",
      "50.00% completed, recall_score = 0.00\n",
      "50.20% completed, recall_score = 0.12\n",
      "50.40% completed, recall_score = 0.00\n",
      "50.60% completed, recall_score = 0.00\n",
      "50.80% completed, recall_score = 0.00\n",
      "51.00% completed, recall_score = 0.00\n",
      "51.20% completed, recall_score = 0.00\n",
      "51.40% completed, recall_score = 0.00\n",
      "51.60% completed, recall_score = 0.06\n",
      "51.80% completed, recall_score = 0.00\n",
      "52.00% completed, recall_score = 0.10\n",
      "52.20% completed, recall_score = 0.25\n",
      "52.40% completed, recall_score = 0.06\n",
      "52.60% completed, recall_score = 0.00\n",
      "52.80% completed, recall_score = 0.00\n",
      "53.00% completed, recall_score = 0.00\n",
      "53.20% completed, recall_score = 0.07\n",
      "53.40% completed, recall_score = 0.00\n",
      "53.60% completed, recall_score = 0.00\n",
      "53.80% completed, recall_score = 0.00\n",
      "54.00% completed, recall_score = 0.00\n",
      "54.20% completed, recall_score = 0.11\n",
      "54.40% completed, recall_score = 0.08\n",
      "54.60% completed, recall_score = 0.00\n",
      "54.80% completed, recall_score = 0.00\n",
      "55.00% completed, recall_score = 0.00\n",
      "55.20% completed, recall_score = 0.06\n",
      "55.40% completed, recall_score = 0.00\n",
      "55.60% completed, recall_score = 0.00\n",
      "55.80% completed, recall_score = 0.07\n",
      "56.00% completed, recall_score = 0.05\n",
      "56.20% completed, recall_score = 0.00\n",
      "56.40% completed, recall_score = 0.00\n",
      "56.60% completed, recall_score = 0.00\n",
      "56.80% completed, recall_score = 0.00\n",
      "57.00% completed, recall_score = 0.00\n",
      "57.20% completed, recall_score = 0.00\n",
      "57.40% completed, recall_score = 0.00\n",
      "57.60% completed, recall_score = 0.00\n",
      "57.80% completed, recall_score = 0.07\n",
      "58.00% completed, recall_score = 0.06\n",
      "58.20% completed, recall_score = 0.20\n",
      "58.40% completed, recall_score = 0.00\n",
      "58.60% completed, recall_score = 0.00\n",
      "58.80% completed, recall_score = 0.00\n",
      "59.00% completed, recall_score = 0.00\n",
      "59.20% completed, recall_score = 0.00\n",
      "59.40% completed, recall_score = 0.00\n",
      "59.60% completed, recall_score = 0.00\n",
      "59.80% completed, recall_score = 0.00\n",
      "60.00% completed, recall_score = 0.00\n",
      "60.20% completed, recall_score = 0.00\n",
      "60.40% completed, recall_score = 0.00\n",
      "60.60% completed, recall_score = 0.00\n",
      "60.80% completed, recall_score = 0.00\n",
      "61.00% completed, recall_score = 0.00\n",
      "61.20% completed, recall_score = 0.03\n",
      "61.40% completed, recall_score = 0.00\n",
      "61.60% completed, recall_score = 0.00\n",
      "61.80% completed, recall_score = 0.00\n",
      "62.00% completed, recall_score = 0.00\n",
      "62.20% completed, recall_score = 0.12\n",
      "62.40% completed, recall_score = 0.00\n",
      "62.60% completed, recall_score = 0.04\n",
      "62.80% completed, recall_score = 0.00\n",
      "63.00% completed, recall_score = 0.00\n",
      "63.20% completed, recall_score = 0.00\n",
      "63.40% completed, recall_score = 0.00\n",
      "63.60% completed, recall_score = 0.07\n",
      "63.80% completed, recall_score = 0.00\n",
      "64.00% completed, recall_score = 0.00\n",
      "64.20% completed, recall_score = 0.00\n",
      "64.40% completed, recall_score = 0.00\n",
      "64.60% completed, recall_score = 0.00\n",
      "64.80% completed, recall_score = 0.00\n",
      "65.00% completed, recall_score = 0.00\n",
      "65.20% completed, recall_score = 0.00\n",
      "65.40% completed, recall_score = 0.00\n",
      "65.60% completed, recall_score = 0.14\n",
      "65.80% completed, recall_score = 0.20\n",
      "66.00% completed, recall_score = 0.00\n",
      "66.20% completed, recall_score = 0.00\n",
      "66.40% completed, recall_score = 0.00\n",
      "66.60% completed, recall_score = 0.00\n",
      "66.80% completed, recall_score = 0.00\n",
      "67.00% completed, recall_score = 0.00\n",
      "67.20% completed, recall_score = 0.00\n",
      "67.40% completed, recall_score = 0.00\n",
      "67.60% completed, recall_score = 0.00\n",
      "67.80% completed, recall_score = 0.00\n",
      "68.00% completed, recall_score = 0.00\n",
      "68.20% completed, recall_score = 0.00\n",
      "68.40% completed, recall_score = 0.00\n",
      "68.60% completed, recall_score = 0.00\n",
      "68.80% completed, recall_score = 0.00\n",
      "69.00% completed, recall_score = 0.00\n",
      "69.20% completed, recall_score = 0.00\n",
      "69.40% completed, recall_score = 0.00\n",
      "69.60% completed, recall_score = 0.00\n",
      "69.80% completed, recall_score = 0.08\n",
      "70.00% completed, recall_score = 0.00\n",
      "70.20% completed, recall_score = 0.00\n",
      "70.40% completed, recall_score = 0.00\n",
      "70.60% completed, recall_score = 0.00\n",
      "70.80% completed, recall_score = 0.00\n",
      "71.00% completed, recall_score = 0.09\n",
      "71.20% completed, recall_score = 0.12\n",
      "71.40% completed, recall_score = 0.00\n",
      "71.60% completed, recall_score = 0.00\n",
      "71.80% completed, recall_score = 0.00\n",
      "72.00% completed, recall_score = 1.00\n",
      "72.20% completed, recall_score = 1.00\n",
      "72.40% completed, recall_score = 0.00\n",
      "72.60% completed, recall_score = 0.00\n",
      "72.80% completed, recall_score = 0.00\n",
      "73.00% completed, recall_score = 0.00\n",
      "73.20% completed, recall_score = 0.00\n",
      "73.40% completed, recall_score = 0.00\n",
      "73.60% completed, recall_score = 0.00\n",
      "73.80% completed, recall_score = 0.00\n",
      "74.00% completed, recall_score = 0.00\n",
      "74.20% completed, recall_score = 0.00\n",
      "74.40% completed, recall_score = 0.33\n",
      "74.60% completed, recall_score = 0.00\n",
      "74.80% completed, recall_score = 0.00\n",
      "75.00% completed, recall_score = 0.00\n",
      "75.20% completed, recall_score = 0.00\n",
      "75.40% completed, recall_score = 0.00\n",
      "75.60% completed, recall_score = 0.00\n",
      "75.80% completed, recall_score = 0.00\n",
      "76.00% completed, recall_score = 0.00\n",
      "76.20% completed, recall_score = 0.17\n",
      "76.40% completed, recall_score = 0.00\n",
      "76.60% completed, recall_score = 0.00\n",
      "76.80% completed, recall_score = 0.00\n",
      "77.00% completed, recall_score = 0.08\n",
      "77.20% completed, recall_score = 0.00\n",
      "77.40% completed, recall_score = 0.07\n",
      "77.60% completed, recall_score = 0.00\n",
      "77.80% completed, recall_score = 0.00\n",
      "78.00% completed, recall_score = 0.07\n",
      "78.20% completed, recall_score = 0.00\n",
      "78.40% completed, recall_score = 0.12\n",
      "78.60% completed, recall_score = 0.00\n",
      "78.80% completed, recall_score = 0.00\n",
      "79.00% completed, recall_score = 0.00\n",
      "79.20% completed, recall_score = 0.00\n",
      "79.40% completed, recall_score = 0.11\n",
      "79.60% completed, recall_score = 0.14\n",
      "79.80% completed, recall_score = 0.08\n",
      "80.00% completed, recall_score = 0.00\n",
      "80.20% completed, recall_score = 0.00\n",
      "80.40% completed, recall_score = 0.00\n",
      "80.60% completed, recall_score = 0.00\n",
      "80.80% completed, recall_score = 0.00\n",
      "81.00% completed, recall_score = 0.00\n",
      "81.20% completed, recall_score = 0.00\n",
      "81.40% completed, recall_score = 0.67\n",
      "81.60% completed, recall_score = 0.17\n",
      "81.80% completed, recall_score = 0.00\n",
      "82.00% completed, recall_score = 0.00\n",
      "82.20% completed, recall_score = 0.00\n",
      "82.40% completed, recall_score = 0.00\n",
      "82.60% completed, recall_score = 0.12\n",
      "82.80% completed, recall_score = 0.00\n",
      "83.00% completed, recall_score = 0.17\n",
      "83.20% completed, recall_score = 0.08\n",
      "83.40% completed, recall_score = 0.00\n",
      "83.60% completed, recall_score = 0.00\n",
      "83.80% completed, recall_score = 0.00\n",
      "84.00% completed, recall_score = 0.00\n",
      "84.20% completed, recall_score = 0.00\n",
      "84.40% completed, recall_score = 0.00\n",
      "84.60% completed, recall_score = 0.00\n",
      "84.80% completed, recall_score = 0.00\n",
      "85.00% completed, recall_score = 0.00\n",
      "85.20% completed, recall_score = 0.11\n",
      "85.40% completed, recall_score = 0.00\n",
      "85.60% completed, recall_score = 0.33\n",
      "85.80% completed, recall_score = 0.00\n",
      "86.00% completed, recall_score = 0.00\n",
      "86.20% completed, recall_score = 0.00\n",
      "86.40% completed, recall_score = 0.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.60% completed, recall_score = 0.00\n",
      "86.80% completed, recall_score = 0.04\n",
      "87.00% completed, recall_score = 0.00\n",
      "87.20% completed, recall_score = 0.00\n",
      "87.40% completed, recall_score = 0.00\n",
      "87.60% completed, recall_score = 0.00\n",
      "87.80% completed, recall_score = 0.00\n",
      "88.00% completed, recall_score = 0.00\n",
      "88.20% completed, recall_score = 0.20\n",
      "88.40% completed, recall_score = 0.00\n",
      "88.60% completed, recall_score = 0.00\n",
      "88.80% completed, recall_score = 0.00\n",
      "89.00% completed, recall_score = 0.00\n",
      "89.20% completed, recall_score = 0.05\n",
      "89.40% completed, recall_score = 0.00\n",
      "89.60% completed, recall_score = 0.00\n",
      "89.80% completed, recall_score = 0.00\n",
      "90.00% completed, recall_score = 0.00\n",
      "90.20% completed, recall_score = 0.00\n",
      "90.40% completed, recall_score = 0.00\n",
      "90.60% completed, recall_score = 0.00\n",
      "90.80% completed, recall_score = 0.00\n",
      "91.00% completed, recall_score = 0.00\n",
      "91.20% completed, recall_score = 0.00\n",
      "91.40% completed, recall_score = 0.00\n",
      "91.60% completed, recall_score = 0.00\n",
      "91.80% completed, recall_score = 0.00\n",
      "92.00% completed, recall_score = 0.00\n",
      "92.20% completed, recall_score = 0.00\n",
      "92.40% completed, recall_score = 0.00\n",
      "92.60% completed, recall_score = 0.00\n",
      "92.80% completed, recall_score = 0.00\n",
      "93.00% completed, recall_score = 0.00\n",
      "93.20% completed, recall_score = 0.00\n",
      "93.40% completed, recall_score = 0.00\n",
      "93.60% completed, recall_score = 0.00\n",
      "93.80% completed, recall_score = 0.00\n",
      "94.00% completed, recall_score = 0.25\n",
      "94.20% completed, recall_score = 0.05\n",
      "94.40% completed, recall_score = 0.03\n",
      "94.60% completed, recall_score = 0.00\n",
      "94.80% completed, recall_score = 0.00\n",
      "95.00% completed, recall_score = 0.00\n",
      "95.20% completed, recall_score = 0.00\n",
      "95.40% completed, recall_score = 0.00\n",
      "95.60% completed, recall_score = 0.00\n",
      "95.80% completed, recall_score = 0.00\n",
      "96.00% completed, recall_score = 0.00\n",
      "96.20% completed, recall_score = 0.00\n",
      "96.40% completed, recall_score = 0.00\n",
      "96.60% completed, recall_score = 0.33\n",
      "96.80% completed, recall_score = 0.00\n",
      "97.00% completed, recall_score = 0.05\n",
      "97.20% completed, recall_score = 0.00\n",
      "97.40% completed, recall_score = 0.00\n",
      "97.60% completed, recall_score = 0.33\n",
      "97.80% completed, recall_score = 0.10\n",
      "98.00% completed, recall_score = 0.00\n",
      "98.20% completed, recall_score = 0.00\n",
      "98.40% completed, recall_score = 0.12\n",
      "98.60% completed, recall_score = 0.00\n",
      "98.80% completed, recall_score = 0.00\n",
      "99.00% completed, recall_score = 0.00\n",
      "99.20% completed, recall_score = 0.00\n",
      "99.40% completed, recall_score = 0.00\n",
      "99.60% completed, recall_score = 0.00\n",
      "99.80% completed, recall_score = 0.00\n",
      "100.00% completed, recall_score = 0.00\n",
      "Completed in 209.85s\n"
     ]
    }
   ],
   "source": [
    "# How many users in the test?\n",
    "total = 500\n",
    "# Counter\n",
    "count = 0\n",
    "\n",
    "def recall_score(actual, pred):\n",
    "    actual, pred = set(actual), set(pred)\n",
    "    return len(actual.intersection(pred)) / len(actual)\n",
    "\n",
    "def popular_recommend(row):\n",
    "    actual = row[\"products\"][1:-1]\n",
    "    actual = [int(p.strip()) for p in actual.strip().split(\",\")]\n",
    "    return recall_score(actual, popular_products)\n",
    "\n",
    "def tfidf_recommend(row):\n",
    "    actual = row[\"products\"][1:-1]\n",
    "    actual = [int(p.strip()) for p in actual.strip().split(\",\")]\n",
    "    target_user = tf_idf[row[\"user_id\"] - 1]\n",
    "    similarities = cosine_similarity(tf_idf, target_user, False)\n",
    "    cos_vec = similarities.toarray()\n",
    "    productset_target_user, recommended = generateRecommendations(target_user, cos_vec, 50, 20, df_prior_user_products, df_product_frequency)\n",
    "    global count\n",
    "    count += 1\n",
    "    print(\"{:.2f}% completed, recall_score = {:.2f}\".format(count / total * 100.0, recall_score(actual, recommended)))    \n",
    "    return recall_score(actual, recommended)\n",
    "\n",
    "def build_eval_df(filepath, df_user_products_test, subset=None):\n",
    "    start = time.time()\n",
    "    print(\"Building dataframe with recall values ...\")\n",
    "    \n",
    "    df_eval = df_user_products_test.copy()\n",
    "    if subset:\n",
    "        df_eval = df_eval[:subset].copy()\n",
    "    df_eval[\"popular_score\"] = df_eval.apply(popular_recommend, axis=1)\n",
    "    df_eval[\"tfidf_score\"] = df_eval.apply(tfidf_recommend, axis=1)\n",
    "    df_eval.to_csv(filepath) #, index_label=False)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))    \n",
    "\n",
    "\n",
    "# Get the dataframe with recall values of the baseline and the model\n",
    "REBUILD_EVAL_DF = False\n",
    "subset = 500\n",
    "eval_path = \"../data/eval/eval_{}.csv\".format(subset if subset is not None else \"full\")\n",
    "if REBUILD_EVAL_DF or not Path(eval_path).exists():\n",
    "    build_eval_df(eval_path, df_user_products_test, subset=subset)\n",
    "df_eval = pd.read_csv(eval_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0.031384215308010936\n",
      "Baseline: 0.06807380013600955\n"
     ]
    }
   ],
   "source": [
    "# Mean recall scores\n",
    "model_mean_recall, baseline_mean_recall = np.mean(df_eval[\"tfidf_score\"]), np.mean(df_eval[\"popular_score\"])\n",
    "print(\"Model: {}\".format(model_mean_recall))\n",
    "print(\"Baseline: {}\".format(baseline_mean_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
