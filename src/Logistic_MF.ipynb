{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Utility Matrix\n",
    "utility_random=np.random.randint(5, size=(1000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticMF():\n",
    "\n",
    "    def __init__(self, counts, num_factors, reg_param=0.6, gamma=1.0,\n",
    "                 iterations=30):\n",
    "        self.counts = counts\n",
    "        self.num_users = counts.shape[0]\n",
    "        self.num_items = counts.shape[1]\n",
    "        self.num_factors = num_factors\n",
    "        self.iterations = iterations\n",
    "        self.reg_param = reg_param\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def train_model(self):\n",
    "\n",
    "        self.ones = np.ones((self.num_users, self.num_items))\n",
    "        self.user_vectors = np.random.normal(size=(self.num_users,\n",
    "                                                   self.num_factors))\n",
    "        self.item_vectors = np.random.normal(size=(self.num_items,\n",
    "                                                   self.num_factors))\n",
    "        self.user_biases = np.random.normal(size=(self.num_users, 1))\n",
    "        self.item_biases = np.random.normal(size=(self.num_items, 1))\n",
    "\n",
    "        user_vec_deriv_sum = np.zeros((self.num_users, self.num_factors))\n",
    "        item_vec_deriv_sum = np.zeros((self.num_items, self.num_factors))\n",
    "        user_bias_deriv_sum = np.zeros((self.num_users, 1))\n",
    "        item_bias_deriv_sum = np.zeros((self.num_items, 1))\n",
    "        for i in range(self.iterations):\n",
    "            t0 = time.time()\n",
    "            # Fix items and solve for users\n",
    "            # take step towards gradient of deriv of log likelihood\n",
    "            # we take a step in positive direction because we are maximizing LL\n",
    "            user_vec_deriv, user_bias_deriv = self.deriv(True)\n",
    "            user_vec_deriv_sum += np.square(user_vec_deriv)\n",
    "            user_bias_deriv_sum += np.square(user_bias_deriv)\n",
    "            vec_step_size = self.gamma / np.sqrt(user_vec_deriv_sum)\n",
    "            bias_step_size = self.gamma / np.sqrt(user_bias_deriv_sum)\n",
    "            self.user_vectors += vec_step_size * user_vec_deriv\n",
    "            self.user_biases += bias_step_size * user_bias_deriv\n",
    "\n",
    "            # Fix users and solve for items\n",
    "            # take step towards gradient of deriv of log likelihood\n",
    "            # we take a step in positive direction because we are maximizing LL\n",
    "            item_vec_deriv, item_bias_deriv = self.deriv(False)\n",
    "            item_vec_deriv_sum += np.square(item_vec_deriv)\n",
    "            item_bias_deriv_sum += np.square(item_bias_deriv)\n",
    "            vec_step_size = self.gamma / np.sqrt(item_vec_deriv_sum)\n",
    "            bias_step_size = self.gamma / np.sqrt(item_bias_deriv_sum)\n",
    "            self.item_vectors += vec_step_size * item_vec_deriv\n",
    "            self.item_biases += bias_step_size * item_bias_deriv\n",
    "            t1 = time.time()\n",
    "\n",
    "            print ('iteration %i finished in %f seconds' % (i + 1, t1 - t0))\n",
    "\n",
    "    def deriv(self, user):\n",
    "        if user:\n",
    "            vec_deriv = np.dot(self.counts, self.item_vectors)\n",
    "            bias_deriv = np.expand_dims(np.sum(self.counts, axis=1), 1)\n",
    "\n",
    "        else:\n",
    "            vec_deriv = np.dot(self.counts.T, self.user_vectors)\n",
    "            bias_deriv = np.expand_dims(np.sum(self.counts, axis=0), 1)\n",
    "        A = np.dot(self.user_vectors, self.item_vectors.T)\n",
    "        A += self.user_biases\n",
    "        A += self.item_biases.T\n",
    "        A = np.exp(A)\n",
    "        A /= (A + self.ones)\n",
    "        A = (self.counts + self.ones) * A\n",
    "\n",
    "        if user:\n",
    "            vec_deriv -= np.dot(A, self.item_vectors)\n",
    "            bias_deriv -= np.expand_dims(np.sum(A, axis=1), 1)\n",
    "            # L2 regularization\n",
    "            vec_deriv -= self.reg_param * self.user_vectors\n",
    "        else:\n",
    "            vec_deriv -= np.dot(A.T, self.user_vectors)\n",
    "            bias_deriv -= np.expand_dims(np.sum(A, axis=0), 1)\n",
    "            # L2 regularization\n",
    "            vec_deriv -= self.reg_param * self.item_vectors\n",
    "        return (vec_deriv, bias_deriv)\n",
    "\n",
    "    def log_likelihood(self):\n",
    "        loglik = 0\n",
    "        A = np.dot(self.user_vectors, self.item_vectors.T)\n",
    "        A += self.user_biases\n",
    "        A += self.item_biases.T\n",
    "        B = A * self.counts\n",
    "        loglik += np.sum(B)\n",
    "\n",
    "        A = np.exp(A)\n",
    "        A += self.ones\n",
    "\n",
    "        A = np.log(A)\n",
    "        A = (self.counts + self.ones) * A\n",
    "        loglik -= np.sum(A)\n",
    "\n",
    "        # L2 regularization\n",
    "        loglik -= 0.5 * self.reg_param * np.sum(np.square(self.user_vectors))\n",
    "        loglik -= 0.5 * self.reg_param * np.sum(np.square(self.item_vectors))\n",
    "        return loglik\n",
    "\n",
    "    def print_vectors(self):\n",
    "        user_vecs_file = open('logmf-user-vecs-%i' % self.num_factors, 'w')\n",
    "        for i in range(self.num_users):\n",
    "            vec = ' '.join(map(str, self.user_vectors[i]))\n",
    "            line = '%i\\t%s\\n' % (i, vec)\n",
    "            user_vecs_file.write(line)\n",
    "        user_vecs_file.close()\n",
    "        item_vecs_file = open('logmf-item-vecs-%i' % self.num_factors, 'w')\n",
    "        for i in range(self.num_items):\n",
    "            vec = ' '.join(map(str, self.item_vectors[i]))\n",
    "            line = '%i\\t%s\\n' % (i, vec)\n",
    "            item_vecs_file.write(line)\n",
    "        item_vecs_file.close()\n",
    "        \n",
    "    def recommend(self, userid, N=10):\n",
    "        user = self.user_vectors[i]\n",
    "        # calculate the top N items, removing the users own liked items from the results\n",
    "        liked = set(self.counts.indices)\n",
    "        scores = self.item_vectors.dot(user)\n",
    "        count = N + len(liked)\n",
    "        \n",
    "        if count < len(scores):\n",
    "            ids = np.argpartition(scores, -count)[-count:]\n",
    "            best = sorted(zip(ids, scores[ids]), key=lambda x: -x[1])\n",
    "        else:\n",
    "            best = sorted(enumerate(scores), key=lambda x: -x[1])\n",
    "        return list(itertools.islice((rec for rec in best if rec[0] not in liked), N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
