{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "import implicit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def sparsity(matrix):\n",
    "    total_size = matrix.shape[0] * matrix.shape[1]\n",
    "    actual_size = matrix.size\n",
    "    sparsity = (1 - (actual_size / total_size)) * 100\n",
    "    return(sparsity)\n",
    "\n",
    "\n",
    "def timestamp():\n",
    "    now = datetime.now()\n",
    "    return \"{}_{}_{}_{}{}\".format(now.year, now.month, now.day, now.hour, now.minute)\n",
    "\n",
    "\n",
    "def get_k_popular(k, df_merged_order_products_prior):\n",
    "    popular_products = list(df_merged_order_products_prior[\"product_id\"].value_counts().head(k).index)\n",
    "    return popular_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order datasets\n",
    "df_order_products_prior = pd.read_csv(\"../data/order_products__prior.csv\")\n",
    "df_order_products_train = pd.read_csv(\"../data/order_products__train.csv\")\n",
    "df_orders = pd.read_csv(\"../data/orders.csv\") \n",
    "\n",
    "# Products\n",
    "df_products = pd.read_csv(\"../data/products.csv\")\n",
    "# Merged prior orders and products\n",
    "df_merged_order_products_prior = pd.merge(df_order_products_prior, df_products, on=\"product_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_data(test_data_path, df_orders, df_order_products_train):\n",
    "    start = time.time()\n",
    "    print(\"Creating test data ...\")\n",
    "\n",
    "    # Read train csv\n",
    "    df_order_user_current = df_orders.loc[(df_orders.eval_set == \"train\")].reset_index()\n",
    "    df_order_user_current = df_order_user_current[[\"order_id\", \"user_id\"]]\n",
    "    \n",
    "    # Sanity check #1: `current_order_user_df` and `df_order_products_train` should have the same number of \n",
    "    # unique order ids\n",
    "    assert len(df_order_user_current[\"order_id\"].unique()) == len(df_order_products_train[\"order_id\"].unique())\n",
    "\n",
    "    # Convert train dataframe to a similar format\n",
    "    df_order_products_test = df_order_products_train[[\"order_id\", \"product_id\"]]\n",
    "    df_order_products_test = df_order_products_test.groupby(\"order_id\")[\"product_id\"].apply(list).reset_index().rename(columns={\"product_id\": \"products\"})\n",
    "\n",
    "    # Sanity check #2: `df_order_products_test` and `df_order_user_current` should have the same number of \n",
    "    # records before attempting to merge them\n",
    "    assert df_order_products_test.size == df_order_user_current.size\n",
    "\n",
    "    # Merge on order id\n",
    "    df_user_products_test = pd.merge(df_order_user_current, df_order_products_test, on=\"order_id\")\n",
    "    df_user_products_test = df_user_products_test[[\"user_id\", \"products\"]]\n",
    "\n",
    "    # Write to disk\n",
    "    df_user_products_test.to_csv(test_data_path, index_label=False)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "\n",
    "\n",
    "# Get test data\n",
    "REBUILD_TEST_DATA = False\n",
    "test_data_path = \"../data/user_products__test.csv\"\n",
    "if REBUILD_TEST_DATA or not Path(test_data_path).is_file():\n",
    "    make_test_data(test_data_path, df_orders, df_order_products_train)\n",
    "df_user_products_test = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Product Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating prior user product data frame ...\n",
      "Completed in 22.41s\n",
      "Creating product user matrix ...\n",
      "Completed in 10.83s\n"
     ]
    }
   ],
   "source": [
    "def build_prior_user_product_df(df_orders, df_order_products_prior):\n",
    "    start = time.time()\n",
    "    print(\"Creating prior user product data frame ...\")\n",
    "    \n",
    "    # Consider ony \"prior\" orders and remove all columns except `user_id` from `df_orders`\n",
    "    df_order_user_prior = df_orders.loc[df_orders.eval_set == \"prior\"]\n",
    "    df_order_user_prior = df_order_user_prior[[\"order_id\", \"user_id\"]]\n",
    "    \n",
    "    # Remove all columns except order_id and user_id from df_orders and \n",
    "    # merge the above on `order_id` and remove `order_id`\n",
    "    df_merged = pd.merge(df_order_user_prior, df_order_products_prior[[\"order_id\", \"product_id\"]], on=\"order_id\")\n",
    "    df_user_product_prior = df_merged[[\"user_id\", \"product_id\"]]\n",
    "    df_user_product_prior = df_user_product_prior.groupby([\"user_id\", \"product_id\"]).size().reset_index().rename(columns={0:\"quantity\"})\n",
    "    \n",
    "    # Make the dataframe a sparse matrix\n",
    "    df_user_product_prior[\"user_id\"] = df_user_product_prior[\"user_id\"].astype(\"category\")\n",
    "    df_user_product_prior[\"product_id\"] = df_user_product_prior[\"product_id\"].astype(\"category\")\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "    return df_user_product_prior\n",
    "\n",
    "\n",
    "def build_product_user_matrix(matrix_path, df_user_product_prior):\n",
    "    start = time.time()\n",
    "    print(\"Creating product user matrix ...\")\n",
    "    \n",
    "    # Make the dataframe a sparse matrix\n",
    "    df_user_product_prior[\"user_id\"] = df_user_product_prior[\"user_id\"].astype(\"category\")\n",
    "    df_user_product_prior[\"product_id\"] = df_user_product_prior[\"product_id\"].astype(\"category\")\n",
    "    product_user_matrix = sparse.coo_matrix((df_user_product_prior[\"quantity\"],\n",
    "                                            (df_user_product_prior[\"product_id\"].cat.codes.copy(),\n",
    "                                             df_user_product_prior[\"user_id\"].cat.codes.copy())))\n",
    "    \n",
    "    sparse.save_npz(matrix_path, product_user_matrix)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "\n",
    "\n",
    "# Build dataframe of users, products and quantity bought using prior datasets\n",
    "df_user_product_prior = build_prior_user_product_df(df_orders, df_order_products_prior)\n",
    "\n",
    "# Get the `product x user` matrix\n",
    "REBUILD_MATRIX = False\n",
    "matrix_path = \"../data/product_user_matrix.npz\"\n",
    "if REBUILD_MATRIX or not Path(matrix_path).is_file():\n",
    "    build_product_user_matrix(matrix_path, df_user_product_prior)\n",
    "product_user_matrix = sparse.load_npz(matrix_path).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User=1 bought product=196 10 times\n",
    "assert product_user_matrix[195, 0] == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.8700882953749"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity(product_user_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "temp = product_user_matrix * 15\n",
    "print(temp[195, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with alpha: 15 and factors: 100 ...\n",
      "Completed in 114.34s\n"
     ]
    }
   ],
   "source": [
    "def build_imf(prod_user_matrix, **kwargs):\n",
    "    start = time.time()\n",
    "    \n",
    "    # Build model\n",
    "    print(\"Building model with alpha: {} and factors: {} ...\".format(kwargs[\"alpha\"], kwargs[\"factors\"]))\n",
    "    model = AlternatingLeastSquares(factors=kwargs[\"factors\"])\n",
    "    model.approximate_similar_items = False\n",
    "    model.fit((prod_user_matrix * kwargs[\"alpha\"]).astype(\"double\"))\n",
    "\n",
    "    # Save model to disk\n",
    "    with open(kwargs[\"path\"], \"wb+\") as f:\n",
    "        pickle.dump(model, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "\n",
    "# Specify model params and build it\n",
    "model_params = {\"alpha\": 15, \"factors\": 100}\n",
    "model_params[\"path\"] = \"../models/imf/imf_a{}_f{}.imf\".format(model_params[\"alpha\"], model_params[\"factors\"])\n",
    "\n",
    "REBUILD_MODEL = True\n",
    "if REBUILD_MODEL or not Path(model_params[\"path\"]).exists():\n",
    "    build_imf(product_user_matrix, **model_params)\n",
    "with open(model_params[\"path\"], \"rb\") as f:\n",
    "    imf_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id product_id  quantity\n",
       "0       1        196        10\n",
       "1       1      10258         9\n",
       "2       1      10326         1\n",
       "3       1      12427        10\n",
       "4       1      13032         3"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_product_prior.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps user_id: user_cat_code\n",
    "u_dict = {uid:i for i, uid in enumerate(df_user_product_prior[\"user_id\"].cat.categories)}\n",
    "\n",
    "# Maps product_cat_code: product_id\n",
    "p_dict = dict(enumerate(df_user_product_prior[\"product_id\"].cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend items for a user\n",
    "user_id = 1\n",
    "recommendations = imf_model.recommend(u_dict[user_id], product_user_matrix.T, N = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_user_product_prior.loc[df_user_product_prior.user_id == user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_p_m = product_user_matrix.T\n",
    "# print(set(u_p_m[u_dict[user_id]].indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual products bought by user 1\n",
      "['Soda', 'Organic String Cheese', '0% Greek Strained Yogurt', 'XL Pick-A-Size Paper Towel Rolls', 'Milk Chocolate Almonds', 'Pistachios', 'Cinnamon Toast Crunch', 'Aged White Cheddar Popcorn', 'Organic Whole Milk', 'Organic Half & Half', 'Zero Calorie Cola']\n",
      "\n",
      "Recommendations for user 1\n",
      "['Organic Half & Half', 'Trail Mix', '0% Greek Strained Yogurt', 'Clementines', 'Extra Fancy Unsalted Mixed Nuts', 'Soda', 'Original Beef Jerky', \"Crunchy Oats 'n Honey Granola Bars\", 'Zero Calorie Cola', 'Milk Chocolate Almonds']\n"
     ]
    }
   ],
   "source": [
    "# Actual \n",
    "row = df_user_products_test.loc[df_user_products_test.user_id == user_id]\n",
    "actual = list(row[\"products\"])\n",
    "actual = actual[0][1:-1]\n",
    "actual = list(np.array([p.strip() for p in actual.strip().split(\",\")]).astype(np.int64))\n",
    "act_products = []\n",
    "for pid in actual:\n",
    "    act_products.extend((df_products.loc[df_products.product_id == pid].product_name).tolist())\n",
    "print(\"Actual products bought by user {}\\n{}\".format(user_id, act_products))\n",
    "\n",
    "# Recommended\n",
    "r = [p_dict[r[0]] for r in recommendations] # Takes the product_cat_code and maps to product_id\n",
    "rec_products = []\n",
    "for pid in r:\n",
    "    rec_products.extend((df_products.loc[df_products.product_id == pid].product_name).tolist())\n",
    "print(\"\\nRecommendations for user {}\\n{}\".format(user_id, rec_products))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_products = get_k_popular(10, df_merged_order_products_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0.14335396125057287\n",
      "Popular: 0.06973728391982736\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Evaluating model ...\")\n",
    "    \n",
    "def recall_score(actual, pred):\n",
    "    actual, pred = set(actual), set(pred)\n",
    "    return len(actual.intersection(pred)) / len(actual)\n",
    "\n",
    "\n",
    "user_product_matrix = product_user_matrix.T #.tocsr()\n",
    "model_recalls = []\n",
    "popular_recalls = []\n",
    "\n",
    "for index, row in df_user_products_test.iterrows():\n",
    "    try:\n",
    "        actual = row[\"products\"][1:-1]\n",
    "        actual = [int(p.strip()) for p in actual.strip().split(\",\")]\n",
    "    \n",
    "        recommended = imf_model.recommend(u_dict[row[\"user_id\"]], user_product_matrix, N=10)\n",
    "        recommended = [p_dict[r[0]] for r in recommended]\n",
    "        \n",
    "        model_recalls.append(recall_score(actual, recommended))\n",
    "        popular_recalls.append(recall_score(actual, popular_products))\n",
    "\n",
    "    \n",
    "model_mean_recall = np.mean(model_recalls)\n",
    "popular_mean_recall = np.mean(popular_recalls)\n",
    "\n",
    "print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "\n",
    "print(\"Model: {}\".format(model_mean_recall))\n",
    "print(\"Popular: {}\".format(popular_mean_recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
